<!doctype html>
<html lang="en">
<head>
    <title>Probability for Engineers - Leo Qi</title>
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="description" content="ECE 203 course notes" />
    <link rel="stylesheet" href="/assets/latex.vercel.app.style.min.css" />
    <script id="MathJax-script" async src="/assets/npm.mathjax3.es5.tex-mml-chtml.js"></script>
    <link rel="stylesheet" href="/assets/latex.vercel.app.prism.css" />
    <script async defer src="/assets/npm.prism.min.js"></script>
    <link rel="icon" href="/favicon.ico" />
</head>
<body class="libertinus">
  <header>
    <h1>Probability for Engineers</h1>
    <p class="author">Leo Qi <br> December 3rd, 2024</p>
  </header>
  <div class="abstract">
    <h2>Abstract</h2>
    <p>Let's document our discovery of the ideas of probability.</p>
  </div>
  <nav role="navigation" class="toc">
    <h2>Contents</h2>
    <ol>
      <li><a href="#probability-axioms">The axioms of probability theory</a></li>
      <li><a href="#random-variables">Random variables</a></li>
    </ol>
  </nav>
  <main>
  <article class="indent-pars">
    <h2 id="probability-axioms">The axioms of probability theory</h2>
    <div class="definition">
      A probability space is a triplet \((\Omega, \mathcal{F}, P)\).
      \(\Omega\) is a nonempty set called the <em>sample space</em>,
      \(\mathcal{F}\) is a set of subsets of \(\Omega\) called <em>events</em>,
      and \(P\) is called a <em>probability measure</em> on \(\mathcal{F}\).
      <span class="sidenote">
        A probability measure is a measure, which is a function satisfying
        certain properties. We define additional axioms it must satisfy.
      </span>
    </div>
    <div class="definition">
      \(\Omega\) is a nonempty set called the <em>sample space</em>. Each
      element \(\omega \in \Omega\) is called an <em>outcome</em>.
    </div>
    <div class="definition">
      Events \(A_i\in\mathcal{F}\) are mutually exclusive, also known as disjoint,
      if \(A_i\cap A_j = \emptyset\) for all \(i\ne j\).
    </div>
    <p>
      We can now define the function that assigns probabilities to events
      in the sample space. This function must satisfy The axioms of probability theory
      theory.
    </p>
    <div class="definition">
      A probability measure is any measure \(P\) on \(\mathcal{F}\)
      that satisfies The axioms of probability theory theory:

      <ol>
        <li>\(P(A) \ge 0\, \forall A\in\mathcal{F}\)</li>
        <li>\(P(\Omega) = 1\)</li>
        <li>If \(A_1, A_2, \ldots\) are disjoint events, then
          \(P(\bigcup_{i=1}^\infty A_i) = \sum_{i=1}^\infty P(A_i)\)</li>
      </ol>
    </div>
    <p>
      The probability measure assigns a real number to each event that
      represents how likely it is to happen. This is called the <em>probability</em>
      of the event. For the math to make sense, this number must be nonnegative.
      The probability of the entire sample space is 1, so any event that has
      probability 1 is certain to happen. We can also derive more properties from
      these axioms. For any subsets \(A, B, C\in\mathcal{F}\):
      <span class="sidenote">
        \(P\) did not have to be defined this way. The only
        requirement is that it is a &#8220;positive continuous monotonic function.&#8221;
        An alternate definition could have been from infinity (impossible)
        <em>down</em> to one (certain)! <sup><a href="#fn1" id="ref1">1</a></sup>
      </span>
    </p>
    <ol>
      <li>\(A\subseteq B \implies P(A) \le P(B)\)</li>
      <li>\(P(A^c) = 1 - P(A)\)</li>
      <li>\(P(A\cup B) = P(A) + P(B) - P(A\cap B)\)</li>
      <li>\(P(\emptyset) = 0\)</li>
    </ol>

    <h2 id="random-variables">Random variables</h2>
    <div class="definition">
      A random variable is a function \(X:\Omega\to\mathbb{R}\) that is
      \(\mathcal{F}\) measurable.<sup><a href="#fn2" id="ref2">2</a></sup>

      <span class="sidenote">
        This means that for any number \(c\),
        \(\{\omega\in\Omega: X(\omega) \le c\}\in\mathcal{F}\)
      </span>
    </div>
    <p>
      If the sample space is finite or countably infinite, \(\mathcal{F}\) is
      most often defined to be the power set of \(\Omega\), and any function from
      \(\Omega\) to \(\mathbb{R}\) will be \(\mathcal{F}\) measurable and thus a
      random variable.
      Therefore, for practical purposes we may assume that any function that
      maps events (which have corresponding probabilities) to real numbers is a
      random variable.
    <p>
    <p>
      This is extremely useful, because we can now give values to events to
      model real-world phenomena. For example, we can define one random variable
      \(X\) that represents the number of heads in a series of coin flips to talk
      about the probability, instead of using the events themselves.
    </p>

    <h2>Bayes' theorem</h2>
    <ul>
      <li>Tests are not events. We have a cancer test, separate from the event
      of actually having cancer.</li>
      <li>Tests are flawed. They may detect things that don't exist (false 
      positives) or fail to detect things that do exist (false negatives).</li>
      <li>False positives skew results. Suppose the test is 99% accurate. If
      the disease is rare, the test will be wrong more often than right.</li>
      <li>People prefer natural numbers. Saying &#8220;1 in 1000&#8221; is more
      understandable than &#8220;0.1%&#8221;.</li>
      <li>Even science is a test. Scientific experients are potentially flawed
        and need to be treated accordingly. There is a test for a phenomenon and
        then there is the event of the phenomenon itself.</li>
    </ul>
    <p>
      Bayes' theorem converts the results from your test into the real probability
      of the event.<sup><a href="#fn3" id="ref3">3</a></sup> We can correct for
      measurement errors if you know the real
      probabilities and the chance of a false positive and false negative, and
      relate the actual probability to the measured test probability.
    </p>
    <p>
      This is finding \(P[H|E]\), the chance that a hypothesis is true given
      evidence \(E\), starting from \(P[E|H]\), the chance that the evidence
      appears when the hypothesis is true.

      \[P[H|E] = \frac{P[E|H]P[H]}{P[E|H]P[H] + P[E|H^c]P[H^c]}\]
    </p>

    <div class="footnotes">
      <p class="no-indent">Last updated: 2024-12-03 14:03 EST</p>
      <p class="no-indent" id="fn1">
        [1] E. T. Jaynes, <em>Probability theory: the logic of science.</em>
        Cambridge University Press, 2003. <a href="#ref1">&#x21A9;</a>
      </p>
      <p class="no-indent" id="fn2">
        [2] B. Hajek, <em>Random processes for engineers.</em>
        Cambridge University Press, 2015. <a href="#ref2">&#x21A9;</a>
      </p>
      <p class="no-indent" id="fn3">
        [3] K. Azad, &#8220;An intuitive (and short) explanation of bayes' theorem,&#8221;
        Better Explained. <a href="#ref3">&#x21A9;</a>
      </p>
      <p class="no-indent" id="fn4">
        [4] K. R. Davidson, &#8220;Measure Theory - Notes for Pure Math 451,&#8221;
        University of Waterloo, 2022. <a href="#ref4">&#x21A9;</a>
      </p>
      <p class="no-indent" id="fn5">
        [5] P. Mitran, &#8220;Lecture notes for ECE 203,&#8221;
        University of Waterloo, 2024. <a href="#ref5">&#x21A9;</a>
      </p>
    </div>
  </article>
</main>
</body>
</html>
